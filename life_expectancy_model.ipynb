{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "life_expectancy_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaya-shankar/education-impact/blob/master/life_expectancy_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFiMWKD-aEI_"
      },
      "source": [
        "### Model Performace History\n",
        "\n",
        "1.   Cosidering life expectancy as input\n",
        "      \n",
        "      1. *Training using max no of countries:*\\\n",
        "          **MSE**: 1.421960711479187\n",
        "          \n",
        "      2. *Training using min no of countries:*\\\n",
        "          **MSE**: 1.6800711154937744\n",
        "\n",
        "      3. *Training using only common countries:*\\\n",
        "          **MSE**: 1.5712116956710815\n",
        "\n",
        "2.   Not cosidering life expectancy as input\n",
        "      1. *Trained using max no of countries:*\\\n",
        "          **MSE**: 1.9395439624786377\n",
        "\n",
        "      2. *Trained using min no of countries*:\\\n",
        "          **MSE**: 2.161480665206909\n",
        "\n",
        "      3. *Trained using only common countries*:\\\n",
        "          **MSE**: 2.10016131401062\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5tBhvAJeBj7",
        "outputId": "230ee151-eae3-49cd-fcf6-3bd3d10bbb66"
      },
      "source": [
        "!rm -rf education-impact"
      ],
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'education-impact': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLCGn-YlJ5k5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8ecaa06-92a6-4fbf-c825-8a84e1315640"
      },
      "source": [
        "!git clone https://github.com/jaya-shankar/education-impact.git\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'education-impact'...\n",
            "remote: Enumerating objects: 364, done.\u001b[K\n",
            "remote: Counting objects: 100% (364/364), done.\u001b[K\n",
            "remote: Compressing objects: 100% (306/306), done.\u001b[K\n",
            "remote: Total 364 (delta 182), reused 175 (delta 55), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (364/364), 3.89 MiB | 9.70 MiB/s, done.\n",
            "Resolving deltas: 100% (182/182), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jo8dc6Xv7sPc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "648b0207-06a5-43a9-9e19-dde4ff087db7"
      },
      "source": [
        "!pip install tensorflow_decision_forests\n",
        "!pip install wurlitzer\n",
        "!pip install seaborn"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_decision_forests\n",
            "  Downloading tensorflow_decision_forests-0.2.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (17.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 17.1 MB 336 kB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorflow_decision_forests) (1.15.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from tensorflow_decision_forests) (1.1.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorflow_decision_forests) (1.19.5)\n",
            "Requirement already satisfied: tensorflow~=2.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_decision_forests) (2.7.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from tensorflow_decision_forests) (0.37.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from tensorflow_decision_forests) (0.12.0)\n",
            "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.7.0->tensorflow_decision_forests) (2.7.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.7.0->tensorflow_decision_forests) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.7.0->tensorflow_decision_forests) (0.22.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.7.0->tensorflow_decision_forests) (3.17.3)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.7.0->tensorflow_decision_forests) (2.7.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.7.0->tensorflow_decision_forests) (2.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.7.0->tensorflow_decision_forests) (3.10.0.2)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.7.0->tensorflow_decision_forests) (1.6.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.7.0->tensorflow_decision_forests) (1.42.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.7.0->tensorflow_decision_forests) (1.13.3)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.7.0->tensorflow_decision_forests) (2.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.7.0->tensorflow_decision_forests) (12.0.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.7.0->tensorflow_decision_forests) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.7.0->tensorflow_decision_forests) (3.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.7.0->tensorflow_decision_forests) (3.3.0)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.7.0->tensorflow_decision_forests) (0.4.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.7.0->tensorflow_decision_forests) (1.1.2)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow~=2.7.0->tensorflow_decision_forests) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow~=2.7.0->tensorflow_decision_forests) (3.3.6)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow~=2.7.0->tensorflow_decision_forests) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow~=2.7.0->tensorflow_decision_forests) (1.35.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow~=2.7.0->tensorflow_decision_forests) (57.4.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow~=2.7.0->tensorflow_decision_forests) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow~=2.7.0->tensorflow_decision_forests) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow~=2.7.0->tensorflow_decision_forests) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow~=2.7.0->tensorflow_decision_forests) (1.8.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow~=2.7.0->tensorflow_decision_forests) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow~=2.7.0->tensorflow_decision_forests) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow~=2.7.0->tensorflow_decision_forests) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow~=2.7.0->tensorflow_decision_forests) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow~=2.7.0->tensorflow_decision_forests) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow~=2.7.0->tensorflow_decision_forests) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow~=2.7.0->tensorflow_decision_forests) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow~=2.7.0->tensorflow_decision_forests) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow~=2.7.0->tensorflow_decision_forests) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow~=2.7.0->tensorflow_decision_forests) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow~=2.7.0->tensorflow_decision_forests) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow~=2.7.0->tensorflow_decision_forests) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->tensorflow_decision_forests) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->tensorflow_decision_forests) (2018.9)\n",
            "Installing collected packages: tensorflow-decision-forests\n",
            "Successfully installed tensorflow-decision-forests-0.2.1\n",
            "Collecting wurlitzer\n",
            "  Downloading wurlitzer-3.0.2-py3-none-any.whl (7.3 kB)\n",
            "Installing collected packages: wurlitzer\n",
            "Successfully installed wurlitzer-3.0.2\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (0.11.2)\n",
            "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.1.5)\n",
            "Requirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.7/dist-packages (from seaborn) (3.2.2)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.19.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (3.0.6)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23->seaborn) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=2.2->seaborn) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNc6Or80qBwS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "750f5262-7f1b-4c9b-fbb7-3ad1d62ab780"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import seaborn as sns\n",
        "import tensorflow_decision_forests as tfdf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from wurlitzer import sys_pipes"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Failure to load the custom c++ tensorflow ops. This error is likely caused the version of TensorFlow and TensorFlow Decision Forests are not compatible.\n",
            "WARNING:root:TF Parameter Server distributed training not available.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHtPKJNNQ7Zv",
        "cellView": "code"
      },
      "source": [
        "#@title Default title text\n",
        "root = \"education-impact/datasets/\" \n",
        "datasets_path = {\n",
        "                    \"infant_mortality\"                :  root+ \"Infant_Mortality_Rate.csv\",\n",
        "                    \"child_mortality\"                 :  root+ \"child_mortality_0_5_year_olds_dying_per_1000_born.csv\",\n",
        "                    \"children_per_woman\"              :  root+ \"children_per_woman_total_fertility.csv\",\n",
        "                    \"co2_emissions\"                   :  root+ \"co2_emissions_tonnes_per_person.csv\",\n",
        "                    \"population\"                      :  root+ \"converted_pop.csv\",\n",
        "                    \"population_density\"              :  root+ \"population_per_area.csv\",\n",
        "                    \"gdp_growth\"                      :  root+ \"gdp_per_capita_yearly_growth.csv\",\n",
        "                    \"Avg_daily_income_ppp\"            :  root+ \"mincpcap_cppp.csv\",\n",
        "                    \"gdppercapita_us_infla_adjust\"    :  root+ \"gdppercapita_us_inflation_adjusted.csv\",\n",
        "                    \"gini_index\"                      :  root+ \"gini.csv\",\n",
        "                    \"life_expectancy\"                 :  root+ \"life_expectancy_years.csv\",\n",
        "                    \"poverty_index\"                   :  root+ \"mincpcap_cppp.csv\",\n",
        "                    \"people_in_poverty\"               :  root+ \"number_of_people_in_poverty.csv\",\n",
        "                    \"ratio_b/g_in_primary\"            :  root+ \"ratio_of_girls_to_boys_in_primary_and_secondary_education_perc.csv\",\n",
        "                    \"wcde-25--34\"                     :  root+ \"wcde-25--34.csv\",\n",
        "                    \"20-24-In_Primary_OL\"             :  root+ \"In_Primary_OL.csv\",\n",
        "                    \"20-24-Primary_OL\"                :  root+ \"Primary_OL.csv\",\n",
        "                    \"20-24-Lower_Secondary_OL\"        :  root+ \"Lower_Secondary_OL.csv\",\n",
        "                    \"20-24_female-In_Primary_OL\"      :  root+ \"female_In_Primary_OL.csv\",\n",
        "                    \"20-24_female-Primary_OL\"         :  root+ \"female_Primary_OL.csv\",\n",
        "                    \"20-24_female-Lower_Secondary_OL\" :  root+ \"female_Lower_Secondary_OL.csv\"\n",
        "                }"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIKRh4fhKg13"
      },
      "source": [
        "datasets_to_plot = [\n",
        "            \"infant_mortality\",\n",
        "            \"child_mortality\",\n",
        "            \"children_per_woman\",\n",
        "            \"co2_emissions\",\n",
        "            \"gini_index\",\n",
        "            \"gdppercapita_us_infla_adjust\",\n",
        "            \"20-24-In_Primary_OL\",\n",
        "            \"20-24-Primary_OL\",\n",
        "            \"20-24-Lower_Secondary_OL\",\n",
        "            \"population\",\n",
        "            \"population_density\",\n",
        "            \"20-24_female-In_Primary_OL\",\n",
        "            \"20-24_female-Primary_OL\" ,\n",
        "            \"20-24_female-Lower_Secondary_OL\",\n",
        "            \"life_expectancy\"\n",
        "            ]\n",
        "\n",
        "# creating a list of all countries & years\n",
        "countries   = find_common_countries(datasets_to_plot)\n",
        "years       = [y for y in range(1960,2015-PREDICT_FUTURE+1)]\n",
        "keys        = generate_indices(countries, years)\n",
        "\n",
        "combined_df = load_datasets_to_pd(datasets_to_plot,keys,include_output=False)"
      ],
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcPACrFkpg8C"
      },
      "source": [
        "n = len(datasets_to_plot)\n",
        "r = math.ceil(math.sqrt(n))\n",
        "i=0\n",
        "for m in range(r):\n",
        "  plt = sns.pairplot(combined_df,diag_kind=\"kde\", y_vars=[\"life_expectancy\"], x_vars=[datasets_to_plot[i] for i in range(r*m,min(n,r*(m+1)))], height=4,dropna=True)\n",
        "  plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWHauD_9RN8n"
      },
      "source": [
        "def get_countries_count(datasets):\n",
        "  for dataset in datasets:\n",
        "    df = pd.read_csv(datasets_path[dataset])\n",
        "    count = len(set(df.Country.unique()))\n",
        "    print(f\"{'Factor: ' + dataset:<40} count: {count}\")\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpydOBe_ZESB"
      },
      "source": [
        "def find_common_countries(datasets):\n",
        "  common_countries = set()\n",
        "  for dataset in datasets:\n",
        "    countries_list = list(pd.read_csv(datasets_path[dataset]).Country)\n",
        "    countries_list = set(map(lambda x: x.lower(), countries_list))\n",
        "    if common_countries == set():\n",
        "      common_countries = countries_list\n",
        "    else:\n",
        "      common_countries = common_countries.intersection(countries_list)\n",
        "  return list(common_countries)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcGs5bV_OlyL"
      },
      "source": [
        "def generate_indices(countries,years):\n",
        "  keys=[]\n",
        "  for y in years:\n",
        "    for c in countries:\n",
        "      keys.append((c,str(y)))\n",
        "  return keys"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c83F6Wgdqr64"
      },
      "source": [
        "def load_datasets_to_pd(datasets,keys,include_output=True):\n",
        "  combined_df = pd.DataFrame(keys,columns=['country','year'])\n",
        "  for dataset in datasets:\n",
        "    combined_df[dataset] = [math.nan]*len(combined_df)\n",
        "    df = pd.read_csv(datasets_path[dataset])\n",
        "    df[\"Country\"] = df[\"Country\"].str.lower()\n",
        "    df.set_index(\"Country\", inplace=True)\n",
        "    for e in range(len(combined_df)):\n",
        "      country = combined_df.iloc[e].country\n",
        "      year    = combined_df.iloc[e].year\n",
        "      combined_df.at[e,dataset] = df.loc[country][year]\n",
        "\n",
        "  if include_output:\n",
        "    label = \"o_\"+OUTPUT\n",
        "    combined_df[label] = [math.nan]*len(combined_df)\n",
        "    df = pd.read_csv(datasets_path[OUTPUT])\n",
        "    df[\"Country\"] = df[\"Country\"].str.lower()\n",
        "    df.set_index(\"Country\", inplace=True)\n",
        "    for e in range(len(combined_df)):\n",
        "      country = combined_df.iloc[e].country\n",
        "      year    = int(combined_df.iloc[e].year)\n",
        "      combined_df.at[e,label] = df.loc[country][str( year + PREDICT_FUTURE )]\n",
        "    # combined_df.set_index([\"country\",\"year\"], inplace=True)\n",
        "  return combined_df\n",
        "\n",
        "  "
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7bwYaCKRrbH"
      },
      "source": [
        "def add_n_yrs_old_dataset(input_df,dataset,years):\n",
        "  dataset_pf = pd.read_csv(datasets_path[dataset])\n",
        "  dataset_pf[\"Country\"] = dataset_pf[\"Country\"].str.lower()\n",
        "  dataset_pf.set_index(\"Country\", inplace=True)\n",
        "\n",
        "  label = dataset+\"_\"+str(years)+\"_before\"\n",
        "  input_df[label] = [math.nan]*len(input_df)\n",
        "\n",
        "  for e in range(len(input_df)):\n",
        "    country = input_df.iloc[e].country\n",
        "    year    = int(input_df.iloc[e].year)\n",
        "    try:\n",
        "      input_df.at[e,label] = dataset_pf.loc[country][str( year - years )]\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "  return input_df"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAi9JoDdGuhE"
      },
      "source": [
        "def combine_dfs(X,y):\n",
        "  label = y.columns[0]\n",
        "  X[label] = y\n",
        "  X.dropna(subset=[label],inplace=True)\n",
        "  return X"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhHeM9gKVimG"
      },
      "source": [
        "## Main Function starts from here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQlw2De3EPX-"
      },
      "source": [
        "datasets = [\n",
        "            # \"infant_mortality\",\n",
        "            # \"life_expectancy\",\n",
        "            # \"child_mortality\",\n",
        "            \"children_per_woman\",\n",
        "            \"co2_emissions\",\n",
        "            \"gini_index\",\n",
        "            \"gdppercapita_us_infla_adjust\",\n",
        "            \"20-24-In_Primary_OL\",\n",
        "            \"20-24-Primary_OL\",\n",
        "            # \"20-24-Lower_Secondary_OL\",\n",
        "            \"population\",\n",
        "            \"20-24_female-In_Primary_OL\",\n",
        "            \"20-24_female-Primary_OL\" ,\n",
        "            # \"female_wcde-Lower_Secondary_OL\"\n",
        "            ]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEv-zMFlFgCm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fe9d431-ff57-4d1f-c79d-19b9c2ef06bf"
      },
      "source": [
        "PREDICT_FUTURE  = 10\n",
        "OUTPUT         = 'life_expectancy'\n",
        "get_countries_count(datasets)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Factor: children_per_woman               count: 202\n",
            "Factor: co2_emissions                    count: 194\n",
            "Factor: gini_index                       count: 195\n",
            "Factor: gdppercapita_us_infla_adjust     count: 207\n",
            "Factor: 20-24-In_Primary_OL              count: 202\n",
            "Factor: 20-24-Primary_OL                 count: 202\n",
            "Factor: population                       count: 197\n",
            "Factor: 20-24_female-In_Primary_OL       count: 202\n",
            "Factor: 20-24_female-Primary_OL          count: 202\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lCbc1WbKgia"
      },
      "source": [
        "# creating a list of all countries & years\n",
        "countries = find_common_countries(datasets)\n",
        "years     = [y for y in range(1960,2015-PREDICT_FUTURE+1)]\n",
        "keys      = generate_indices(countries, years)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1W2z1TcszrP"
      },
      "source": [
        "input_df            = load_datasets_to_pd(datasets,keys)\n",
        "input_df            = add_n_yrs_old_dataset(input_df,\"gdppercapita_us_infla_adjust\",20)\n",
        "output_df           = input_df[[\"o_\" + OUTPUT]]\n",
        "input_df.drop(labels=[\"o_\" + OUTPUT], axis = 1, inplace=True)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kgk60lsfU1AB",
        "outputId": "f1fae2a3-c25b-4f03-eacd-9edc7c10fe90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        }
      },
      "source": [
        "input_df"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>country</th>\n",
              "      <th>year</th>\n",
              "      <th>children_per_woman</th>\n",
              "      <th>co2_emissions</th>\n",
              "      <th>gini_index</th>\n",
              "      <th>gdppercapita_us_infla_adjust</th>\n",
              "      <th>20-24-In_Primary_OL</th>\n",
              "      <th>20-24-Primary_OL</th>\n",
              "      <th>population</th>\n",
              "      <th>20-24_female-In_Primary_OL</th>\n",
              "      <th>20-24_female-Primary_OL</th>\n",
              "      <th>gdppercapita_us_infla_adjust_20_before</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>haiti</td>\n",
              "      <td>1960</td>\n",
              "      <td>6.32</td>\n",
              "      <td>0.0739</td>\n",
              "      <td>59.7</td>\n",
              "      <td>1670.0</td>\n",
              "      <td>89.3</td>\n",
              "      <td>93.7</td>\n",
              "      <td>3870000.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>95.1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>panama</td>\n",
              "      <td>1960</td>\n",
              "      <td>5.87</td>\n",
              "      <td>0.8800</td>\n",
              "      <td>57.4</td>\n",
              "      <td>2710.0</td>\n",
              "      <td>44.5</td>\n",
              "      <td>73.1</td>\n",
              "      <td>1130000.0</td>\n",
              "      <td>43.8</td>\n",
              "      <td>72.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>peru</td>\n",
              "      <td>1960</td>\n",
              "      <td>6.97</td>\n",
              "      <td>0.8050</td>\n",
              "      <td>57.1</td>\n",
              "      <td>2710.0</td>\n",
              "      <td>58.4</td>\n",
              "      <td>65.9</td>\n",
              "      <td>10200000.0</td>\n",
              "      <td>65.3</td>\n",
              "      <td>71.9</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>zambia</td>\n",
              "      <td>1960</td>\n",
              "      <td>7.12</td>\n",
              "      <td>1.4200</td>\n",
              "      <td>66.6</td>\n",
              "      <td>1220.0</td>\n",
              "      <td>71.3</td>\n",
              "      <td>80.8</td>\n",
              "      <td>3070000.0</td>\n",
              "      <td>88.8</td>\n",
              "      <td>93.7</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>bahrain</td>\n",
              "      <td>1960</td>\n",
              "      <td>7.09</td>\n",
              "      <td>3.5400</td>\n",
              "      <td>40.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>81.3</td>\n",
              "      <td>86.2</td>\n",
              "      <td>162000.0</td>\n",
              "      <td>89.1</td>\n",
              "      <td>91.9</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7263</th>\n",
              "      <td>albania</td>\n",
              "      <td>2005</td>\n",
              "      <td>1.75</td>\n",
              "      <td>1.3800</td>\n",
              "      <td>30.7</td>\n",
              "      <td>2680.0</td>\n",
              "      <td>3.7</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3090000.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>5.7</td>\n",
              "      <td>1740.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7264</th>\n",
              "      <td>saudi arabia</td>\n",
              "      <td>2005</td>\n",
              "      <td>3.42</td>\n",
              "      <td>16.6000</td>\n",
              "      <td>40.0</td>\n",
              "      <td>18700.0</td>\n",
              "      <td>6.8</td>\n",
              "      <td>18.7</td>\n",
              "      <td>23800000.0</td>\n",
              "      <td>10.3</td>\n",
              "      <td>21.1</td>\n",
              "      <td>15200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7265</th>\n",
              "      <td>ecuador</td>\n",
              "      <td>2005</td>\n",
              "      <td>2.79</td>\n",
              "      <td>2.1700</td>\n",
              "      <td>53.2</td>\n",
              "      <td>4890.0</td>\n",
              "      <td>14.7</td>\n",
              "      <td>38.7</td>\n",
              "      <td>13800000.0</td>\n",
              "      <td>14.5</td>\n",
              "      <td>37.2</td>\n",
              "      <td>4210.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7266</th>\n",
              "      <td>luxembourg</td>\n",
              "      <td>2005</td>\n",
              "      <td>1.64</td>\n",
              "      <td>26.5000</td>\n",
              "      <td>30.7</td>\n",
              "      <td>95500.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.7</td>\n",
              "      <td>458000.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>45100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7267</th>\n",
              "      <td>bahamas</td>\n",
              "      <td>2005</td>\n",
              "      <td>1.86</td>\n",
              "      <td>5.6300</td>\n",
              "      <td>43.7</td>\n",
              "      <td>35700.0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>2.2</td>\n",
              "      <td>325000.0</td>\n",
              "      <td>0.7</td>\n",
              "      <td>1.9</td>\n",
              "      <td>32700.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7268 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           country  ... gdppercapita_us_infla_adjust_20_before\n",
              "0            haiti  ...                                    NaN\n",
              "1           panama  ...                                    NaN\n",
              "2             peru  ...                                    NaN\n",
              "3           zambia  ...                                    NaN\n",
              "4          bahrain  ...                                    NaN\n",
              "...            ...  ...                                    ...\n",
              "7263       albania  ...                                 1740.0\n",
              "7264  saudi arabia  ...                                15200.0\n",
              "7265       ecuador  ...                                 4210.0\n",
              "7266    luxembourg  ...                                45100.0\n",
              "7267       bahamas  ...                                32700.0\n",
              "\n",
              "[7268 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRYgp4465ve1"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(input_df, output_df, test_size=0.30, random_state=43)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoY9_jY9n7Wo",
        "outputId": "34409a77-d6d1-48c4-b18b-9840f94959ab"
      },
      "source": [
        "X_train.isna().sum()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "children_per_woman                 0\n",
              "co2_emissions                    104\n",
              "gini_index                         0\n",
              "gdppercapita_us_infla_adjust    1330\n",
              "20-24-In_Primary_OL                0\n",
              "20-24-Primary_OL                   0\n",
              "population                         0\n",
              "20-24_female-In_Primary_OL         0\n",
              "20-24_female-Primary_OL            0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sefswM8hpqdg",
        "outputId": "7b30bd23-36c6-4b4b-c4b9-9bf9ff12f357"
      },
      "source": [
        "y_train.isna().sum()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "o_life_expectancy    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2wiwgqk6ZfU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "602ff643-ced1-4127-b4f4-7ea16f0ff24a"
      },
      "source": [
        "\n",
        "# converting pandas to tensorFlow dataset\n",
        "train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(combine_dfs(X_train,y_train), label=\"o_\"+OUTPUT, task=tfdf.keras.Task.REGRESSION)\n",
        "model = tfdf.keras.RandomForestModel(task = tfdf.keras.Task.REGRESSION)\n",
        "\n",
        "model.fit(x=train_ds)\n",
        "# Convert it to a TensorFlow dataset\n",
        "test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(combine_dfs(X_train,y_train), label=\"o_\"+OUTPUT, task=tfdf.keras.Task.REGRESSION)\n",
        "\n",
        "# Evaluate the model\n",
        "model.compile(metrics=[\"mse\"])\n",
        "# Evaluate the model on the test dataset.\n",
        "evaluation = model.evaluate(test_ds, return_dict=True)\n",
        "print(OUTPUT.upper())\n",
        "print(evaluation)\n",
        "print()\n",
        "print(f\"MSE: {evaluation['mse']}\")\n",
        "print(f\"RMSE: {math.sqrt(evaluation['mse'])}\")\n",
        "print()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "80/80 [==============================] - 5s 67ms/step\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.0000e+00 - mse: 2.1254\n",
            "LIFE_EXPECTANCY\n",
            "{'loss': 0.0, 'mse': 2.125378131866455}\n",
            "\n",
            "MSE: 2.125378131866455\n",
            "RMSE: 1.4578676661022616\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9km9jt9mBIvM"
      },
      "source": [
        "tfdf.model_plotter.plot_model_in_colab(model, tree_idx=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dd29dXaO8AB"
      },
      "source": [
        "# %set_cell_height 300\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2kQcZeipBBi"
      },
      "source": [
        "# XGBoost Regressor "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aHtQM7tpLel"
      },
      "source": [
        "from xgboost import XGBRegressor\n",
        "from numpy import absolute\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedKFold"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUjow-k8pfm6"
      },
      "source": [
        "input_df            = load_datasets_to_pd(datasets,keys)\n",
        "output_df           = input_df[[\"o_\" + OUTPUT]]\n",
        "input_df.drop(labels=[\"o_\" + OUTPUT], axis = 1, inplace=True)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKmquB59pfbK"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(input_df, output_df, test_size=0.30, random_state=43)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBHXJM4upIxM"
      },
      "source": [
        "# create an xgboost regression model\n",
        "model = XGBRegressor()"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sn5NoJpfqQn-"
      },
      "source": [
        "# define model evaluation method\n",
        "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "# evaluate model\n",
        "scores = cross_val_score(model, X_train, y_train, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPi4apj5qY0U",
        "outputId": "a6072f84-80c6-4cd8-ccee-0c6a8e5f8740",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "scores = absolute(scores)\n",
        "print('Mean MAE: %.3f (%.3f)' % (scores.mean(), scores.std()) )"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean MAE: 2.665 (0.124)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ck40I_2pO2t8"
      },
      "source": [
        "# DNN Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoTPvb0hO2BL"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Flatten\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error \n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sb\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings \n",
        "warnings.filterwarnings('ignore')\n",
        "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
        "from xgboost import XGBRegressor"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOgX1z4ssI_r"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAYG6P8ysI8I"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSrlOe2ysI2e"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9EhQCMjsIzH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7hOC8ZBsIwK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Rj_nYZ0sItM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHcOgjQOsIjf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pavoB83cgMS_"
      },
      "source": [
        "from the above output\n",
        "- **malnutrition & people in povery** have least no of countries\n",
        "- **infant mortality & gdp per captia** have highest no of countries\n",
        "\n",
        "*Doubt:* Does having more data for one factor will make the decision tree bias?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26MX_yiOLQM1"
      },
      "source": [
        "###Steps\n",
        "1. create a csv file such that each row contains all values of particular year & country present\n",
        "2. the output for each row is year + 40 years corresponding value \n",
        "    1. **outputs** - life expectany, education level, gdp\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UMi5KTtyRsq"
      },
      "source": [
        "From above output\n",
        "- if we dont drop any rows our table size = 4256 entries\n",
        "- if we drop rows containing any if all of outputs missing then our table size = 3039 entries\n",
        "- if we drop rows containing any one of output missing then our table size = 1745 entries\n",
        "\n",
        "so, I think its is better to go with second choice and build different models, but not sure it will not effect performance of the model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlvdCI-pzVEd"
      },
      "source": [
        "now we have the dataframe containing both inputs and ouputs,our next step is\n",
        "1. split the data into train & test data\n",
        "  1. try to split data based on continents to reduce bias\n",
        "2. build DF model using tensorflow\n",
        "3. check the accuracy of the model"
      ]
    }
  ]
}