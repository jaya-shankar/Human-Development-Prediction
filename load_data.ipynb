{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "load_data.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaya-shankar/education-impact/blob/master/load_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5tBhvAJeBj7",
        "outputId": "a9aad74b-dec0-4194-e45a-6e7fea4210c4"
      },
      "source": [
        "!rm -rf education-impact\n",
        "!rm education-impact"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'education-impact': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLCGn-YlJ5k5"
      },
      "source": [
        "!git clone https://github.com/jaya-shankar/education-impact.git\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHtPKJNNQ7Zv"
      },
      "source": [
        "root = \"education-impact/\" \n",
        "datasets_path = {\n",
        "                    \"infant_mortality\"              :  root+ \"datasets/Infant_Mortality_Rate.csv\",\n",
        "                    \"child_mortality\"               :  root+ \"datasets/child_mortality_0_5_year_olds_dying_per_1000_born.csv\",\n",
        "                    \"children_per_woman\"            :  root+ \"datasets/children_per_woman_total_fertility.csv\",\n",
        "                    \"co2_emissions\"                 :  root+\"datasets/co2_emissions_tonnes_per_person.csv\",\n",
        "                    \"population\"                    :  root+ \"datasets/converted_pop.csv\",\n",
        "                    \"food_supply\"                   :  root+ \"datasets/food_supply_kilocalories_per_person_and_day.csv\",\n",
        "                    \"gdp_per_captia\"                :  root+ \"datasets/gdp_per_capita_yearly_growth.csv\",\n",
        "                    \"gini_index\"                    :  root+ \"datasets/gini.csv\",\n",
        "                    \"life_expectancy\"               :  root+ \"datasets/life_expectancy_years.csv\",\n",
        "                    \"malnutrition\"                  :  root+ \"datasets/malnutrition_weight_for_age_percent_of_children_under_5.csv\",\n",
        "                    \"poverty_index\"                 :  root+ \"datasets/mincpcap_cppp.csv\",\n",
        "                    \"maternal_mortality\"            :  root+ \"datasets/mmr_who.csv\",\n",
        "                    \"people_in_poverty\"             :  root+ \"datasets/number_of_people_in_poverty.csv\",\n",
        "                    \"primary_completion\"            :  root+ \"datasets/primary_school_completion_percent_of_girls.csv\",\n",
        "                    \"ratio_b/g_in_primary\"          :  root+ \"datasets/ratio_of_girls_to_boys_in_primary_and_secondary_education_perc.csv\",\n",
        "                    \"wcde-15--24\"                   :  root+ \"datasets/wcde-15--24.csv\",\n",
        "                    \"wcde-25--34\"                   :  root+ \"datasets/wcde-25--34.csv\",\n",
        "                    \"wcde-35--44\"                   :  root+ \"datasets/wcde-35--44.csv\",\n",
        "                    \"wcde-45--54\"                   :  root+ \"datasets/wcde-45--54.csv\",\n",
        "                    \"wcde-55--64\"                   :  root+ \"datasets/wcde-55--64.csv\",\n",
        "                    \"wcde-65--74\"                   :  root+ \"datasets/wcde-65--74.csv\",\n",
        "                    \"wcde-75--84\"                   :  root+ \"datasets/wcde-75--84.csv\",\n",
        "                    \"wcde-85--94\"                   :  root+ \"datasets/wcde-85--94.csv\",\n",
        "                    \"wcde-95--\"                     :  root+ \"datasets/wcde-95--.csv\",\n",
        "                 \n",
        "                }"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeM0rvqVRLLD"
      },
      "source": [
        "datasets_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNc6Or80qBwS"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWHauD_9RN8n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27bfb1f5-6de3-4d4f-d861-7ca838011374"
      },
      "source": [
        "countries_arr = []\n",
        "for path in datasets_path:\n",
        "  df = read_csv(datasets_path[path])\n",
        "  print(f\"{'Factor: ' + path:<30} count: {len(set(df.Country.unique()))}\")\n",
        "  "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Factor: infant_mortality       count: 266\n",
            "Factor: child_mortality        count: 197\n",
            "Factor: children_per_woman     count: 202\n",
            "Factor: co2_emissions          count: 194\n",
            "Factor: population             count: 197\n",
            "Factor: food_supply            count: 179\n",
            "Factor: gdp_per_captia         count: 221\n",
            "Factor: gini_index             count: 195\n",
            "Factor: life_expectancy        count: 195\n",
            "Factor: malnutrition           count: 156\n",
            "Factor: poverty_index          count: 195\n",
            "Factor: maternal_mortality     count: 184\n",
            "Factor: people_in_poverty      count: 145\n",
            "Factor: primary_completion     count: 195\n",
            "Factor: ratio_b/g_in_primary   count: 200\n",
            "Factor: wcde-15--24            count: 202\n",
            "Factor: wcde-25--34            count: 202\n",
            "Factor: wcde-35--44            count: 202\n",
            "Factor: wcde-45--54            count: 202\n",
            "Factor: wcde-55--64            count: 202\n",
            "Factor: wcde-65--74            count: 202\n",
            "Factor: wcde-75--84            count: 202\n",
            "Factor: wcde-85--94            count: 202\n",
            "Factor: wcde-95--              count: 202\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pavoB83cgMS_"
      },
      "source": [
        "from the above output\n",
        "- **malnutrition & people in povery** have least no of countries\n",
        "- **infant mortality & gdp per captia** have highest no of countries\n",
        "\n",
        "*Doubt:* Does having more data for one factor will make the decision tree bias?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26MX_yiOLQM1"
      },
      "source": [
        "###Steps\n",
        "1. create a csv file such that each row contains all values of particular year & country present\n",
        "2. the output for each row is year + 40 years corresponding value \n",
        "    1. **outputs** - life expectany, education level, gdp\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fowCPSIPOupC"
      },
      "source": [
        "PREDICT_FUTURE = 40\n",
        "OUTPUTS = ['life_expectancy', 'gdp_per_captia', 'primary_completion' ]"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lCbc1WbKgia"
      },
      "source": [
        "\n",
        "countries = list(read_csv('education-impact/datasets/Infant_Mortality_Rate.csv').Country.unique())\n",
        "years = [y for y in range(1960,2015-PREDICT_FUTURE+1)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcGs5bV_OlyL"
      },
      "source": [
        "keys=[]\n",
        "for y in years:\n",
        "  for c in countries:\n",
        "    keys.append((c,str(y)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GF8pxSpGlaKM"
      },
      "source": [
        "big_dic = {k : [] for k in keys}\n",
        "for path in datasets_path:\n",
        "  df = pd.read_csv(datasets_path[path])\n",
        "  df.set_index(\"Country\", inplace=True)\n",
        "  for k in keys:\n",
        "    try:\n",
        "      big_dic[k].append(df.loc[k[0]][k[1]])\n",
        "    except:\n",
        "      big_dic[k].append(np.NaN)\n",
        " "
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Auq0KuvwqOG-",
        "outputId": "4d52338a-02ed-4f53-d626-79027ee368a0"
      },
      "source": [
        "print(len(datasets_path))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgqcguWjsUGI"
      },
      "source": [
        "for output_path in OUTPUTS:\n",
        "  df = pd.read_csv(datasets_path[output_path])\n",
        "  df.set_index(\"Country\", inplace=True)\n",
        "  for k in keys:\n",
        "    try:\n",
        "      big_dic[k].append(df.loc[k[0]][str(int(k[1])+PREDICT_FUTURE)])\n",
        "    except:\n",
        "      big_dic[k].append(np.NaN)\n"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVnfofKptBRt"
      },
      "source": [
        "columns = [k for k in datasets_path ]\n",
        "output_columns = [\"o_\"+o for o in OUTPUTS]\n",
        "columns.extend(output_columns)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1W2z1TcszrP"
      },
      "source": [
        "input_df = pd.DataFrame.from_dict(big_dic,orient='index', columns = columns)\n",
        "modified_input = input_df.dropna(subset=[\"o_\"+o for o in OUTPUTS])\n",
        "modified_input2 = input_df.dropna(subset=[\"o_\"+o for o in OUTPUTS],how='all')\n",
        "print(input_df.info())\n",
        "print(modified_input.info())\n",
        "print(modified_input2.info())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UMi5KTtyRsq"
      },
      "source": [
        "From above output\n",
        "- if we dont drop any rows our table size = 4256 entries\n",
        "- if we drop rows containing any if all of outputs missing then our table size = 3039 entries\n",
        "- if we drop rows containing any one of output missing then our table size = 1745 entries\n",
        "\n",
        "so, I think its is better to go with second choice and build different models, but not sure it will not effect performance of the model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlvdCI-pzVEd"
      },
      "source": [
        "now we have the dataframe containing both inputs and ouputs,our next step is\n",
        "1. split the data into train & test data\n",
        "2. build DF model using tensorflow\n",
        "3. check the accuracy of the model"
      ]
    }
  ]
}